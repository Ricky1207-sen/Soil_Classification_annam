{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport timm\n\n# Define file paths\nLABELS_CSV = './data/train_labels.csv'\nTRAIN_PATH = './data/train'\n\n# Label encoding dictionaries\nlabel2id = {\"Alluvial soil\": 0, \"Black Soil\": 1, \"Clay soil\": 2, \"Red soil\": 3}\nid2label = {v: k for k, v in label2id.items()}\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SoilDataset(Dataset):\n    def __init__(self, df, image_dir, transform=None, is_test=False):\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.image_dir, row['image_id'])\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.is_test:\n            return image, row['image_id']\n        else:\n            label = label2id[row['soil_type']]\n            return image, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(0.3, 0.3, 0.3, 0.05),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, smoothing=0.1):\n        super().__init__()\n        self.smoothing = smoothing\n        self.confidence = 1.0 - smoothing\n\n    def forward(self, x, target):\n        log_probs = torch.nn.functional.log_softmax(x, dim=-1)\n        true_dist = torch.zeros_like(log_probs)\n        true_dist.fill_(self.smoothing / (x.size(1) - 1))\n        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n\n    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate(model, loader, device):\n    model.eval()\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for images, labels in tqdm(loader, desc=\"Validating\", leave=False):\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.numpy())\n\n    report = classification_report(all_labels, all_preds, output_dict=True, zero_division=0)\n    per_class_f1 = [report[str(i)]['f1-score'] for i in range(4)]\n    return accuracy_score(all_labels, all_preds), per_class_f1, min(per_class_f1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_kfold_training(df, k=3, epochs=10):\n    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    all_models = []\n    all_min_f1 = []\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['soil_type'])):\n        print(f\"\\n----- Fold {fold+1}/{k} -----\")\n        train_df = df.iloc[train_idx].reset_index(drop=True)\n        val_df = df.iloc[val_idx].reset_index(drop=True)\n\n        train_dataset = SoilDataset(train_df, TRAIN_PATH, transform=train_transform)\n        val_dataset = SoilDataset(val_df, TRAIN_PATH, transform=val_transform)\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32)\n\n        model = timm.create_model('convnext_base', pretrained=True, num_classes=4)\n        model.to(device)\n\n        criterion = LabelSmoothingCrossEntropy(0.1)\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n\n        best_min_f1 = 0\n        for epoch in range(epochs):\n            print(f\"Epoch {epoch+1}/{epochs}\")\n            train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n            val_acc, f1s, min_f1 = validate(model, val_loader, device)\n            print(f\"Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}, Min F1: {min_f1:.4f}\")\n\n            if min_f1 > best_min_f1:\n                best_min_f1 = min_f1\n                torch.save(model.state_dict(), f\"best_model_3fold_fold{fold+1}.pth\")\n\n            scheduler.step()\n\n        all_min_f1.append(best_min_f1)\n        all_models.append(f\"best_model_3fold_fold{fold+1}.pth\")\n\n    print(f\"\\nAverage Min F1 across {k} folds: {np.mean(all_min_f1):.4f}\")\n    return all_models\n\nif __name__ == '__main__':\n    labels_df = pd.read_csv(LABELS_CSV)\n    print(\"Starting 3-fold training...\")\n    model_paths = run_kfold_training(labels_df, k=3, epochs=10)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}