{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Import required libraries\nimport pandas as pd  # For handling CSV files and dataframes\nimport numpy as np  # For numerical operations\nimport os  # For file path operations\nimport matplotlib.pyplot as plt  # For plotting graphs\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # For image augmentation and loading\nfrom tensorflow.keras.applications import MobileNetV2  # Pre-trained MobileNetV2 model\nfrom tensorflow.keras.models import Model  # Base class for defining the custom model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D  # Layers to modify base model\nfrom tensorflow.keras.optimizers import Adam  # Optimizer\nfrom tensorflow.keras.callbacks import EarlyStopping  # For stopping training early if no improvement\nfrom tensorflow.keras.preprocessing import image  # For image loading and processing\nfrom sklearn.metrics import f1_score  # For evaluating model performance using F1-score\nimport tensorflow as tf  # TensorFlow framework\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Define important paths and constants\nTRAIN_DIR = \"../data/soil_competition-2025/train\"  # Directory where training images are stored\nTEST_DIR = \"../data/soil_competition-2025/test\"  # Directory where test images are stored\nTRAIN_CSV = \"../data/soil_competition-2025/train_labels.csv\"  # CSV file containing training image IDs\nTEST_CSV = \"../data/soil_competition-2025/test_ids.csv\"  # CSV file containing test image IDs\nIMG_SIZE = (224, 224)  # Input image size (height, width)\nBATCH_SIZE = 32  # Number of images per batch during training","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Load training labels\ndf = pd.read_csv(TRAIN_CSV)  # Read the CSV into a dataframe\ndf[\"label\"] = 1  # Assign label 1 to all training images (since they are all soil)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Define augmentation pipeline to generate negative (non-soil) samples\naugmenter = ImageDataGenerator(\n    rescale=1./255,  # Normalize pixel values\n    rotation_range=30,  # Random rotation\n    brightness_range=[0.2, 0.8],  # Random brightness\n    shear_range=20,  # Shear transformation\n    zoom_range=0.5,  # Zoom in/out\n    horizontal_flip=True,  # Random horizontal flip\n    vertical_flip=True,  # Random vertical flip\n    channel_shift_range=50.0,  # Random color shifts\n    fill_mode=\"nearest\",  # Filling strategy\n    preprocessing_function=lambda x: tf.image.random_contrast(x, 0.5, 1.5)  # Add random contrast\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Function to generate synthetic negative images\ndef generate_negative_samples(df, n=1000):\n    # Use augmenter to generate new negative images based on existing soil images\n    temp_gen = augmenter.flow_from_dataframe(\n        df,\n        directory=TRAIN_DIR,\n        x_col=\"image_id\",  # Column with image filenames\n        y_col=None,  # No labels needed\n        target_size=IMG_SIZE,  # Resize images\n        class_mode=None,\n        batch_size=1,  # Generate one image at a time\n        shuffle=True,\n        seed=42\n    )\n    neg_images = []  # List to store generated negative images\n    for _ in range(n):\n        img = next(temp_gen)[0]  # Fetch one augmented image\n        neg_images.append(img)  # Add to list\n    return np.array(neg_images), np.zeros((n,))  # Return images with label 0 (non-soil)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Create train and validation generators with real soil images\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Rescale and split data\n\n# Create training generator (80% data)\ntrain_gen = datagen.flow_from_dataframe(\n    df,\n    directory=TRAIN_DIR,\n    x_col=\"image_id\",  # Image file name\n    y_col=\"label\",  # Label column\n    target_size=IMG_SIZE,\n    class_mode=\"raw\",  # Return raw labels instead of categorical\n    subset=\"training\",\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\n# Create validation generator (20% data)\nval_gen = datagen.flow_from_dataframe(\n    df,\n    directory=TRAIN_DIR,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    target_size=IMG_SIZE,\n    class_mode=\"raw\",\n    subset=\"validation\",\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Create the base model using MobileNetV2\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))  # Load MobileNetV2 without the top classification layer\n\nx = base_model.output  # Get output from base model\nx = GlobalAveragePooling2D()(x)  # Add a global average pooling layer\nx = Dense(64, activation='relu')(x)  # Add dense layer with 64 neurons\npredictions = Dense(1, activation='sigmoid')(x)  # Final output layer for binary classification\n\nmodel = Model(inputs=base_model.input, outputs=predictions)  # Define the full model\n\n# Freeze base model layers (only train top layers first)\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 8. Generate synthetic negative samples to balance dataset\nneg_images, neg_labels = generate_negative_samples(df, n=len(df))  # Generate same number of negatives as positives","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 9. Collect real soil training images\nX_real, y_real = [], []\nfor _ in range(len(train_gen)):\n    X, y = next(train_gen)  # Get batch of data\n    X_real.append(X)  # Append images\n    y_real.append(y)  # Append labels\n\nX_real = np.concatenate(X_real)  # Combine all real images\ny_real = np.concatenate(y_real)  # Combine all labels\n\n# Combine real soil and synthetic non-soil images\nX_train = np.concatenate([X_real, neg_images])  # All training images\ny_train = np.concatenate([y_real, neg_labels])  # Corresponding labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10. Train model with early stopping to prevent overfitting\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  # Stop training if val_loss doesn't improve for 3 epochs\n# Initial training\nhistory = model.fit(\n    X_train, y_train,  # Input and labels\n    validation_data=val_gen,  # Validation data\n    epochs=10,  # Train for up to 10 epochs\n    batch_size=BATCH_SIZE,\n    callbacks=[early_stop]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 11. Fine-tune top layers of MobileNetV2\nfor layer in base_model.layers[-30:]:  # Unfreeze last 30 layers for fine-tuning\n    layer.trainable = True\n\n# Re-compile model with smaller learning rate for fine-tuning\nmodel.compile(optimizer=Adam(learning_rate=1e-5), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\n# Continue training with unfrozen layers\nhistory_finetune = model.fit(\n    X_train, y_train,\n    validation_data=val_gen,\n    epochs=10,\n    batch_size=BATCH_SIZE,\n    callbacks=[early_stop]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 12. Evaluate model using F1-score on validation set\nval_gen.reset()  # Reset generator state\nval_preds, val_labels = [], []  # Store predictions and labels\n\nfor _ in range(len(val_gen)):\n    batch_x, batch_y = next(val_gen)  # Get batch of validation data\n    pred = model.predict(batch_x)  # Predict on batch\n    val_preds.extend((pred > 0.5).astype(int).flatten())  # Convert probabilities to 0/1\n    val_labels.extend(batch_y.flatten())  # Store true labels\n\nval_f1 = f1_score(val_labels, val_preds)  # Compute F1 score\nprint(f\"Validation F1-score: {val_f1:.4f}\")  # Print result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 13. Save model weights\nmodel.save(\"soil_model_mobilenetv2.h5\")  # Save trained model to disk","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}